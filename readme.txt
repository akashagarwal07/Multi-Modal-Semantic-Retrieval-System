This is the best part about Vector Search. NO, you do not need to train again.

You have already done the heavy lifting (Extraction + Embedding) on your powerful RTX 4500. The "Knowledge" is now stored in the outputs/ folder.

You can move this to a regular laptop or a server with a weak GPU (or even CPU only), and it will work perfectly.

Here is exactly how to migrate.

1. What to Zip (The Transfer List)

You need to zip the following folders and files. Do NOT zip your python environment or cache folders.

Include these:

üìÇ src/ (Your code)

üìÇ appui/ (Your frontend and backend)

üìÇ outputs/ (CRITICAL: Contains your Embeddings, Indexes, and Metadata)

üìÇ pdf_repo/ (Backend needs this to let users download the PDFs)

üìÑ main.py (Just to keep the project complete)

Do NOT Include:

‚ùå yolov8l-doclaynet.pt (You only need this for extracting new PDFs. You don't need it for searching).

‚ùå __pycache__ folders.

‚ùå Any virtual environment folder (like venv or Lib).

2. Setup on the New System (Low GPU)

On the new computer, create a folder (e.g., IR_Search) and unzip your files there.

1. Install Python 3.10
Make sure Python 3.10 is installed.

2. Install Dependencies
Run this command to install the required libraries. Note that we use the CPU version of torch if the GPU is too weak or non-existent, but standard install usually works for both.

code
Powershell
download
content_copy
expand_less
pip install fastapi uvicorn python-multipart aiofiles faiss-cpu transformers torch torchvision pillow numpy

(Note: We use faiss-cpu here because it's easier to install and plenty fast for searching 1600 papers).

3. The "CPU Fallback" Check

Your current code in appui/backend.py is already smart. It has this line:

code
Python
download
content_copy
expand_less
device = "cuda" if torch.cuda.is_available() else "cpu"

On your RTX 4500: It used CUDA (GPU).

On the new System: It will automatically switch to CPU if no NVIDIA GPU is found.

Performance Note:

GPU Search: ~0.05 seconds.

CPU Search: ~0.5 seconds.

User Experience: The user won't notice the difference. CPU is fine for searching.

4. How to Run

On the new system, do not run main.py (that attempts to extract PDFs and requires a heavy GPU).

Only run the Server:
Open the terminal in the folder and run:

code
Powershell
download
content_copy
expand_less
python -m uvicorn appui.backend:app --host 0.0.0.0 --port 8000

First Run: It will download the Jina-CLIP model (approx 1.5GB) from the internet. Make sure the new system has internet access for the first run.

Subsequent Runs: It will load instantly.

Summary

Zip outputs, pdf_repo, src, appui.

Move to new laptop.

Install pip install ...

Run the backend server command.

You are good to go!